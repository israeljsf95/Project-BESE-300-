{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.linalg import norm as tnorm\n",
    "from collections import OrderedDict as od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride =  1, groups = 1,\n",
    "                 use_bn = True, use_drop = True, is_first_block = False):\n",
    "\n",
    "        super(ResBlock, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.groups = groups\n",
    "        self.use_bn = use_bn\n",
    "        self.use_drop = use_drop\n",
    "        self.is_first_block = is_first_block\n",
    "        #first block\n",
    "\n",
    "        self.conv1 = torch.nn.Conv1d(\n",
    "            in_channels = self.in_channels,\n",
    "            out_channels = self.out_channels,\n",
    "            kernel_size = self.kernel_size,\n",
    "            padding = \"same\",\n",
    "            stride = self.stride,\n",
    "            groups = self.groups,\n",
    "            bias = False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(self.out_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.drop1= nn.Dropout(0.1)\n",
    "        self.max_pool = nn.MaxPool1d(self.kernel_size)\n",
    "\n",
    "        #second block\n",
    "        self.bn2 = nn.BatchNorm1d(self.out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.drop2 = nn.Dropout(0.1)\n",
    "        self.conv2 = torch.nn.Conv1d(\n",
    "            in_channels = self.out_channels,\n",
    "            out_channels = self.out_channels,\n",
    "            kernel_size = self.kernel_size,\n",
    "            padding = \"same\",\n",
    "            stride = 1,\n",
    "            groups = self.groups,\n",
    "            bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #First model applying everything\n",
    "        residual = x\n",
    "        out = x\n",
    "\n",
    "        if not self.is_first_block:\n",
    "            if self.use_bn:\n",
    "                out = self.bn1(out)\n",
    "            out = self.relu1(out)\n",
    "            if self.use_drop:\n",
    "                out = self.drop1(out)\n",
    "\n",
    "        out = self.conv1(out)\n",
    "        # the second conv\n",
    "        if self.use_bn:\n",
    "            out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "        if self.use_drop:\n",
    "            out = self.drop2(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        # shortcut\n",
    "        out += residual\n",
    "\n",
    "        return out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(inplanes, planes, kernel_size = 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.conv2 = nn.Conv1d(planes, planes, kernel_size = 3, stride=stride,\n",
    "                               padding = 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.conv3 = nn.Conv1d(planes, planes * 4, kernel_size = 1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm1d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # SE\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.conv_down = nn.Conv1d(\n",
    "            planes * 4, planes // 4, kernel_size = 1, bias=False)\n",
    "        self.conv_up = nn.Conv1d(\n",
    "            planes // 4, planes * 4, kernel_size = 1, bias=False)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        # Downsample\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        out1 = self.global_pool(out)\n",
    "        out1 = self.conv_down(out1)\n",
    "        out1 = self.relu(out1)\n",
    "        out1 = self.conv_up(out1)\n",
    "        out1 = self.sig(out1)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        res = out1 * out + residual\n",
    "        res = self.relu(res)\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "class SEResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes = 100):\n",
    "        self.inplanes = 32\n",
    "        super(SEResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 64, kernel_size = 7, stride=2,\n",
    "                               padding=3, bias=False)\n",
    "        self.conv2 = nn.Conv1d(64, 32, kernel_size = 7, stride = 2,\n",
    "                               padding = 3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool1d(7)\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv1d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size = 1, stride = stride, bias = False),\n",
    "                nn.BatchNorm1d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x.view(x.shape[0], 1, x.shape[-1])\n",
    "\n",
    "class SEResCnn(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, input_din, output_din):\n",
    "\n",
    "        super(SEResCnn, self).__init__()\n",
    "        self.block = block\n",
    "        self.layers = layers\n",
    "        self.input_din = input_din\n",
    "        self.output_din = output_din\n",
    "        self.intermedial_layers = [1024, 512, 256, 128]\n",
    "        self.conv1 = nn.Conv1d(self.intermedial_layers[0], self.intermedial_layers[0], kernel_size = 3, stride = 2, padding=1,\n",
    "                               bias = False)\n",
    "        self.conv2 = nn.Conv1d(self.intermedial_layers[0], self.intermedial_layers[1], kernel_size = 3, stride = 2, padding=1,\n",
    "                               bias = False)\n",
    "        self.conv3 = nn.Conv1d(self.intermedial_layers[1], self.intermedial_layers[2], kernel_size = 3, stride = 2, padding=1,\n",
    "                               bias = False)\n",
    "        self.conv4 = nn.Conv1d(self.intermedial_layers[2], self.intermedial_layers[3], kernel_size = 3, stride=2, padding=1,\n",
    "                               bias = False)\n",
    "        self.bn1 = nn.BatchNorm1d(self.intermedial_layers[0])\n",
    "        self.bn2 = nn.BatchNorm1d(self.intermedial_layers[1])\n",
    "        self.bn3 = nn.BatchNorm1d(self.intermedial_layers[2])\n",
    "        self.bn4 = nn.BatchNorm1d(self.intermedial_layers[3])\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size = 3, stride = 1, padding = 1)\n",
    "\n",
    "        self.se_layer = SEResNet(self.block, self.layers, self.output_din)\n",
    "        self.resblock_layer1 = ResBlock(1, self.intermedial_layers[0], 3, is_first_block = True)\n",
    "        self.resblock_layer2 = ResBlock(self.intermedial_layers[0], self.intermedial_layers[0], 3)\n",
    "        self.resblock_layer3 = ResBlock(self.intermedial_layers[1], self.intermedial_layers[1], 3)\n",
    "        self.resblock_layer4 = ResBlock(self.intermedial_layers[2], self.intermedial_layers[2], 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.se_layer(x)\n",
    "        x = self.resblock_layer1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x1 = self.maxpool(x)\n",
    "\n",
    "        x2 = self.resblock_layer2(x1)\n",
    "        x2 = self.conv2(x2)\n",
    "        x2 = self.bn2(x2)\n",
    "        x2 = self.relu(x2)\n",
    "        x2 = self.maxpool(x2)\n",
    "\n",
    "        x3 = self.resblock_layer3(x2)\n",
    "        x3 = self.conv3(x3)\n",
    "        x3 = self.bn3(x3)\n",
    "        x3 = self.relu(x3)\n",
    "        x3 = self.maxpool(x3)\n",
    "\n",
    "        x4 = self.resblock_layer4(x3)\n",
    "        x4 = self.conv4(x4)\n",
    "        x4 = self.bn4(x4)\n",
    "        x4 = self.relu(x4)\n",
    "        x4 = self.maxpool(x4)\n",
    "\n",
    "        return x1, x2, x3, x4\n",
    "\n",
    "\n",
    "\n",
    "class BPNET_blk1(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, input_din, output_din):\n",
    "\n",
    "        super(BPNET_blk1, self).__init__()\n",
    "        self.block = block\n",
    "        self.layers = layers\n",
    "        self.input_din = input_din\n",
    "        self.output_din = output_din\n",
    "\n",
    "        self.ecg_branch = SEResCnn(block, layers, self.input_din, self.output_din)\n",
    "        self.ppg_branch = SEResCnn(block, layers, self.input_din, self.output_din)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x1 = x[:,:, 1:1250]\n",
    "        x2 = x[:,:, 1250:]\n",
    "        x1_ecg, x2_ecg, x3_ecg, x4_ecg = self.ecg_branch(x1)\n",
    "        x1_ppg, x2_ppg, x3_ppg, x4_ppg = self.ppg_branch(x2)\n",
    "\n",
    "        #Normalizing the Feature Vectors:\n",
    "        #ECG-Norm\n",
    "        aux_1_ecg = tnorm(x1_ecg, ord = 2, keepdim = True, dim = 2)\n",
    "        x1_ecg_norm = x1_ecg / aux_1_ecg\n",
    "        aux_2_ecg = tnorm(x2_ecg, ord = 2, keepdim = True, dim = 2)\n",
    "        x2_ecg_norm = x2_ecg / aux_2_ecg\n",
    "        aux_3_ecg = tnorm(x3_ecg, ord = 2, keepdim = True, dim = 2)\n",
    "        x3_ecg_norm = x3_ecg / aux_3_ecg\n",
    "        aux_4_ecg = tnorm(x4_ecg, ord = 2, keepdim = True, dim = 2)\n",
    "        x4_ecg_norm = x4_ecg / aux_4_ecg\n",
    "\n",
    "        #PPG-Norm\n",
    "        aux_1_ppg = tnorm(x1_ppg, ord = 2, keepdim = True, dim = 2)\n",
    "        x1_ppg_norm = x1_ppg / aux_1_ppg\n",
    "        aux_2_ppg = tnorm(x2_ppg, ord = 2, keepdim = True, dim = 2)\n",
    "        x2_ppg_norm = x2_ppg / aux_2_ppg\n",
    "        aux_3_ppg = tnorm(x3_ppg, ord = 2, keepdim = True, dim = 2)\n",
    "        x3_ppg_norm = x3_ppg / aux_3_ppg\n",
    "        aux_4_ppg = tnorm(x4_ppg, ord = 2, keepdim = True, dim = 2)\n",
    "        x4_ppg_norm = x4_ppg / aux_4_ppg\n",
    "\n",
    "        x1_cat = torch.cat((x1_ecg_norm, x1_ppg_norm), axis = -1)\n",
    "        x2_cat = torch.cat((x2_ecg_norm, x2_ppg_norm), axis = -1)\n",
    "        x3_cat = torch.cat((x3_ecg_norm, x3_ppg_norm), axis = -1)\n",
    "        x4_cat = torch.cat((x4_ecg_norm, x4_ppg_norm), axis = -1)\n",
    "\n",
    "        return x1_cat, x2_cat, x3_cat, x4_cat\n",
    "\n",
    "class FPN_SERESCNN(nn.Module):\n",
    "\n",
    "    def __init__(self, layers, filters_out):\n",
    "\n",
    "        super(FPN_SERESCNN, self).__init__()\n",
    "\n",
    "        self.layers = layers\n",
    "        self.filters_out = filters_out\n",
    "        self.fpn = torchvision.ops.FeaturePyramidNetwork(self.layers, self.filters_out)\n",
    "\n",
    "    def forward(self, x1, x2, x3, x4):\n",
    "\n",
    "        xx = od()\n",
    "        xx['feat4'] = torch.unsqueeze(x1, dim = 2)\n",
    "        xx['feat3'] = torch.unsqueeze(x2, dim = 2)\n",
    "        xx['feat2'] = torch.unsqueeze(x3, dim = 2)\n",
    "        xx['feat1'] = torch.unsqueeze(x4, dim = 2)\n",
    "        out = self.fpn(xx)\n",
    "        aux1 = nn.functional.interpolate(out['feat1'].squeeze(), scale_factor = 2, mode = \"linear\", align_corners = True)\n",
    "        aux3 = out['feat2'].squeeze() + aux1\n",
    "        aux3_2 = nn.functional.interpolate(aux3, scale_factor = 2, mode = 'linear', align_corners = True)\n",
    "        aux4 = out['feat3'].squeeze() + aux3_2\n",
    "        aux4_2 = nn.functional.interpolate(aux4, scale_factor = 2, mode = 'linear', align_corners = True)\n",
    "        final = out['feat4'].squeeze() + aux4_2\n",
    "        return final\n",
    "\n",
    "\n",
    "class BPNET_blk2(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, input_din, output_din, layers_fpn = [1024, 512, 256, 128], filters_out = 5):\n",
    "\n",
    "        super(BPNET_blk2, self).__init__()\n",
    "\n",
    "        self.block = block\n",
    "        self.layers = layers\n",
    "        self.layers_fpn = layers_fpn\n",
    "        self.input_din = input_din\n",
    "        self.output_din = output_din\n",
    "        self.filters_out = filters_out\n",
    "        self.blk1 = BPNET_blk1(self.block, self.layers, self.input_din, 1024)\n",
    "        self.fpn = FPN_SERESCNN(self.layers_fpn, self.filters_out)\n",
    "        self.conv1 = nn.Conv1d(self.filters_out, 32, kernel_size = 3, stride = 1, padding = \"valid\",\n",
    "                               bias = False)\n",
    "        self.conv2 = nn.Conv1d(32, 16, kernel_size = 3, stride = 2, padding = \"valid\",\n",
    "                               bias = False)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(16, 8, kernel_size = 3, stride = 2,  padding = \"valid\",\n",
    "                               bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        xx1, xx2, xx3, xx4 = self.blk1(x)\n",
    "        out = self.fpn(xx1, xx2, xx3, xx4)\n",
    "        out = self.conv1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        return out\n",
    "\n",
    "class BPNET_blk3(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, input_din, output_din, layers_fpn = [1024, 512, 256, 128], filters_out = 5):\n",
    "\n",
    "        super(BPNET_blk3, self).__init__()\n",
    "        self.block = block\n",
    "        self.layers = layers\n",
    "        self.layers_fpn = layers_fpn\n",
    "        self.input_din = input_din\n",
    "        self.output_din = output_din\n",
    "        self.filters_out = filters_out\n",
    "\n",
    "        self.bpnet = BPNET_blk2(self.block, self.layers, self.input_din, self.output_din, self.layers_fpn, self.filters_out)\n",
    "\n",
    "        self.mlp_ecg = nn.Sequential(nn.Linear(in_features = 254*8, out_features = 1024, bias = True),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Linear(in_features = 1024, out_features = 512, bias = True),\n",
    "                                     nn.AdaptiveAvgPool1d(1))\n",
    "\n",
    "        self.mlp_ppg = nn.Sequential(nn.Linear(in_features = 254*8, out_features = 1024, bias = True),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Linear(in_features = 1024, out_features = 512, bias = True),\n",
    "                                     nn.AdaptiveAvgPool1d(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.bpnet(x)\n",
    "        out = out.view(out.shape[0], out.shape[1]*out.shape[2])\n",
    "        y1 = self.mlp_ecg(out)\n",
    "        y2 = self.mlp_ppg(out)\n",
    "\n",
    "        return torch.cat((y1, y2), dim = -1)\n",
    "\n",
    "#Loss function from the paper\n",
    "def loss_bpnet(y, y_pred):\n",
    "    #dim 0 = SBP\n",
    "    #dim 1 = DBP\n",
    "\n",
    "    erro = (y_pred - y)**2\n",
    "    corrcoef = erro\n",
    "    corrcoef = corrcoef[:, 0] / corrcoef[:, 1]\n",
    "\n",
    "    aux = erro[:, 0] + corrcoef*erro[:, 1]\n",
    "\n",
    "    return aux.mean()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inpout shape: torch.Size([64, 1, 1250])\n",
      "output1 shape: torch.Size([64, 1024, 512])\n",
      "output2 shape: torch.Size([64, 512, 256])\n",
      "output3 shape: torch.Size([64, 256, 128])\n",
      "output4 shape: torch.Size([64, 128, 64])\n"
     ]
    }
   ],
   "source": [
    "N = 1250\n",
    "test = torch.rand(64, 1, 1250)\n",
    "\n",
    "#model1 = SEResNet(Bottleneck, [3, 4, 6, 3], 1024)\n",
    "# model2 = ResBlock(1, 512, 3, is_first_block = True)\n",
    "model3 = SEResCnn(Bottleneck, [3, 4, 6, 3], 1, 1024)\n",
    "#out1 = model1(test)\n",
    "# out2 = model2(test)\n",
    "x1,x2,x3,x4 = model3(test)\n",
    "print(f\"inpout shape: {test.shape}\")\n",
    "print(f\"output1 shape: {x1.shape}\")\n",
    "print(f\"output2 shape: {x2.shape}\")\n",
    "print(f\"output3 shape: {x3.shape}\")\n",
    "print(f\"output4 shape: {x4.shape}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inpout shape: torch.Size([12, 1, 2500])\n",
      "output1 shape: torch.Size([12, 1024, 1024])\n",
      "output2 shape: torch.Size([12, 512, 512])\n",
      "output3 shape: torch.Size([12, 256, 256])\n",
      "output3 shape: torch.Size([12, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "test = torch.rand(12, 1, 1250*2)\n",
    "model1 = BPNET_blk1(Bottleneck, [3, 4, 6, 3], 1, 1024)\n",
    "x1,x2,x3,x4 = model1(test)\n",
    "print(f\"inpout shape: {test.shape}\")\n",
    "print(f\"output1 shape: {x1.shape}\")\n",
    "print(f\"output2 shape: {x2.shape}\")\n",
    "print(f\"output3 shape: {x3.shape}\")\n",
    "print(f\"output3 shape: {x4.shape}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[0.7428, 0.7525, 0.0418, 0.5083, 0.2307, 0.7825, 0.8495, 0.1337,\n           0.1783, 0.2107]],\n \n         [[0.3677, 0.2938, 0.5692, 0.4827, 0.6315, 0.7112, 0.8840, 0.4853,\n           0.1218, 0.6406]],\n \n         [[0.3661, 0.1583, 0.0711, 0.8283, 0.0228, 0.3586, 0.7416, 0.3084,\n           0.5966, 0.8224]],\n \n         [[0.0448, 0.3671, 0.9465, 0.5501, 0.4943, 0.2382, 0.4843, 0.6858,\n           0.9965, 0.3052]],\n \n         [[0.7042, 0.4075, 0.6133, 0.2222, 0.0796, 0.6925, 0.9508, 0.7436,\n           0.7198, 0.3171]],\n \n         [[0.5681, 0.8154, 0.5081, 0.5280, 0.5121, 0.2160, 0.2327, 0.8745,\n           0.8192, 0.9995]],\n \n         [[0.6482, 0.9921, 0.0076, 0.3258, 0.1107, 0.6575, 0.8438, 0.5387,\n           0.3134, 0.5029]],\n \n         [[0.5921, 0.6933, 0.3374, 0.2255, 0.9485, 0.5597, 0.0519, 0.1808,\n           0.9089, 0.3794]],\n \n         [[0.5400, 0.4547, 0.9560, 0.5182, 0.9414, 0.3568, 0.5995, 0.1502,\n           0.7529, 0.0997]],\n \n         [[0.8458, 0.0398, 0.2669, 0.8781, 0.0092, 0.0322, 0.4927, 0.6913,\n           0.9963, 0.5187]],\n \n         [[0.8101, 0.1353, 0.2568, 0.2439, 0.5243, 0.1001, 0.8255, 0.5297,\n           0.6082, 0.8649]],\n \n         [[0.7034, 0.7433, 0.1390, 0.2304, 0.4155, 0.2187, 0.1261, 0.3019,\n           0.9385, 0.5777]]]),\n torch.Size([12, 1, 10]))"
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.rand((12, 1, 10))\n",
    "t2, t2.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[1.6909]],\n \n         [[1.7678]],\n \n         [[1.6299]],\n \n         [[1.8513]],\n \n         [[1.9103]],\n \n         [[2.0790]],\n \n         [[1.8189]],\n \n         [[1.7928]],\n \n         [[1.9113]],\n \n         [[1.8822]],\n \n         [[1.7790]],\n \n         [[1.6315]]]),\n torch.Size([12, 1, 1]))"
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_t2 = tnorm(t2, ord = 2, keepdim = True, dim = 2)\n",
    "t2_norm = t2 / norm_t2\n",
    "norm_t2, norm_t2.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[0.4393, 0.4450, 0.0247, 0.3006, 0.1365, 0.4627, 0.5024, 0.0791,\n           0.1054, 0.1246]],\n \n         [[0.2080, 0.1662, 0.3220, 0.2730, 0.3572, 0.4023, 0.5000, 0.2745,\n           0.0689, 0.3623]],\n \n         [[0.2246, 0.0971, 0.0436, 0.5082, 0.0140, 0.2200, 0.4550, 0.1892,\n           0.3660, 0.5045]],\n \n         [[0.0242, 0.1983, 0.5113, 0.2971, 0.2670, 0.1287, 0.2616, 0.3704,\n           0.5383, 0.1648]],\n \n         [[0.3686, 0.2133, 0.3211, 0.1163, 0.0417, 0.3625, 0.4977, 0.3893,\n           0.3768, 0.1660]],\n \n         [[0.2732, 0.3922, 0.2444, 0.2540, 0.2463, 0.1039, 0.1119, 0.4206,\n           0.3941, 0.4807]],\n \n         [[0.3564, 0.5454, 0.0042, 0.1791, 0.0608, 0.3615, 0.4639, 0.2962,\n           0.1723, 0.2765]],\n \n         [[0.3303, 0.3867, 0.1882, 0.1258, 0.5291, 0.3122, 0.0290, 0.1008,\n           0.5070, 0.2116]],\n \n         [[0.2825, 0.2379, 0.5002, 0.2711, 0.4925, 0.1867, 0.3137, 0.0786,\n           0.3939, 0.0521]],\n \n         [[0.4494, 0.0212, 0.1418, 0.4665, 0.0049, 0.0171, 0.2618, 0.3673,\n           0.5293, 0.2756]],\n \n         [[0.4554, 0.0760, 0.1443, 0.1371, 0.2947, 0.0562, 0.4640, 0.2977,\n           0.3419, 0.4862]],\n \n         [[0.4311, 0.4556, 0.0852, 0.1412, 0.2546, 0.1341, 0.0773, 0.1851,\n           0.5753, 0.3541]]]),\n torch.Size([12, 1, 10]))"
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2_norm = t2 / norm_t2\n",
    "t2_norm, t2_norm.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([2.1260, 2.1828, 2.6122, 5.1026, 4.2017, 2.5588, 5.3950, 5.1737, 5.9358,\n        1.4470])"
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2[0, 0, :] / t2_norm[0,0, 0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([0.7428, 0.7525, 0.0418, 0.5083, 0.2307, 0.7825, 0.8495, 0.1337, 0.1783,\n         0.2107]),\n tensor(0.4393))"
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2[0, 0, :], t2_norm[0, 0, 0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[1.0000]],\n\n        [[1.0000]],\n\n        [[1.0000]],\n\n        [[1.0000]],\n\n        [[1.0000]],\n\n        [[1.0000]],\n\n        [[1.0000]],\n\n        [[1.0000]],\n\n        [[1.0000]],\n\n        [[1.0000]],\n\n        [[1.0000]],\n\n        [[1.0000]]])"
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnorm(t2_norm, ord = 2, dim = 2, keepdim = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0.1683, 0.1728, 0.2068, 0.4040, 0.3326, 0.2026, 0.4271, 0.4096,\n          0.4699, 0.1146]],\n\n        [[0.0066, 0.0781, 0.5628, 0.5322, 0.1585, 0.2395, 0.2216, 0.1635,\n          0.4296, 0.2259]],\n\n        [[0.3841, 0.6002, 0.1577, 0.2400, 0.1205, 0.0340, 0.3670, 0.3219,\n          0.2310, 0.3201]],\n\n        [[0.1417, 0.1320, 0.2181, 0.1164, 0.3828, 0.1357, 0.4450, 0.3609,\n          0.3844, 0.5102]],\n\n        [[0.0139, 0.2605, 0.1502, 0.4891, 0.4885, 0.0368, 0.1905, 0.3963,\n          0.2806, 0.3978]],\n\n        [[0.3699, 0.3498, 0.2860, 0.0387, 0.5117, 0.4381, 0.0621, 0.4136,\n          0.1575, 0.0633]],\n\n        [[0.1899, 0.3632, 0.2091, 0.0601, 0.4521, 0.3690, 0.0093, 0.4184,\n          0.4913, 0.1657]],\n\n        [[0.2638, 0.2833, 0.2794, 0.0776, 0.2655, 0.0299, 0.4727, 0.2101,\n          0.4694, 0.4548]],\n\n        [[0.0536, 0.3793, 0.2426, 0.5145, 0.0302, 0.2181, 0.1960, 0.5866,\n          0.3010, 0.0899]],\n\n        [[0.5213, 0.3599, 0.2031, 0.4046, 0.0469, 0.3081, 0.3415, 0.0304,\n          0.1226, 0.4052]],\n\n        [[0.2424, 0.4530, 0.1577, 0.4966, 0.2607, 0.3798, 0.1883, 0.0014,\n          0.4372, 0.1605]],\n\n        [[0.3360, 0.1820, 0.5454, 0.2917, 0.1508, 0.0671, 0.1829, 0.2570,\n          0.5515, 0.2013]]])"
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2_norm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([12, 5, 1, 1024]),\n torch.Size([12, 5, 1, 512]),\n torch.Size([12, 5, 1, 256]),\n torch.Size([12, 5, 1, 128]))"
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = od()\n",
    "xx['feat4'] = torch.unsqueeze(x1, dim = 2)\n",
    "xx['feat3'] = torch.unsqueeze(x2, dim = 2)\n",
    "xx['feat2'] = torch.unsqueeze(x3, dim = 2)\n",
    "xx['feat1'] = torch.unsqueeze(x4, dim = 2)\n",
    "fpn_m = torchvision.ops.FeaturePyramidNetwork([1024, 512, 256, 128], 5)\n",
    "out = fpn_m(xx)\n",
    "out['feat4'].shape, out['feat3'].shape, out['feat2'].shape, out['feat1'].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([12, 5, 1024])"
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux1 = nn.functional.interpolate(out['feat1'].squeeze(), scale_factor = 2, mode = \"linear\", align_corners = True)\n",
    "aux3 = out['feat2'].squeeze() + aux1\n",
    "aux3_2 = nn.functional.interpolate(aux3, scale_factor = 2, mode = 'linear', align_corners = True)\n",
    "aux4 = out['feat3'].squeeze() + aux3_2\n",
    "aux4_2 = nn.functional.interpolate(aux4, scale_factor = 2, mode = 'linear', align_corners = True)\n",
    "final = out['feat4'].squeeze() + aux4_2\n",
    "final.shape\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([64, 1, 2500])"
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.rand((64, 1, 1250*2))\n",
    "test.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([64, 8, 254])"
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = BPNET_blk2(Bottleneck, [3, 4, 6, 3], 1, 1024, [1024, 512, 256, 128], 32)\n",
    "out4 = model4(test)\n",
    "out4.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([64, 2])"
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = BPNET_blk3(Bottleneck, [3, 4, 6, 3], 1, 1024, [1024, 512, 256, 128], 32)\n",
    "out4 = model4(test)\n",
    "out4.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "outputs": [],
   "source": [
    "y_pred = torch.rand((64, 2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.5967, grad_fn=<MeanBackward0>)"
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_bpnet(out4, y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
